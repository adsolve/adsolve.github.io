#### Work Stream 5: Use Cases

Our current use cases and partners are in: [(1)](#ws5a) Multi-modal medical diagnostics and monitoring for cancer and mental health; [(2)](#ws5b) AI support for mental health covering summarisation & dialogue self-management interventions; [(3)](#ws5c) AI legal support covering long-form summarisation and dialogue. We are considering new partners and use cases.

<br>

##### Use case 1: Multi-modal medical diagnostics and monitoring
<span class="anchor-s" id="ws5a"></span>
Patients in the UK have long waits for treatment, often until their condition deteriorates. Many conditions are multi-faceted with long-term changes not captured during single consultations/tests. The integration of longitudinal, heterogeneous, and multi-modal data, such as text (clinician notes, social media content, etc.), scan images, tabular data, phone mobility data, could offer a more complete view resulting in better diagnosis and monitoring of many conditions, including cancer and dementia.

**Key Challenges:** Data diversity & safeguarding; methods for longitudinal, multi-modal, heterogeneous and asynchronous data with sparse ground truth and missing values; evaluation metrics; interpretability and provenance of model outputs; the need for temporal reasoning and situational awareness, implications of the lack thereof. From an RAI perspective we must plan for unexpected consequences (e.g. balance between treatment availability and faster diagnosis). For monitoring, broader ethical and social challenges must be considered (e.g., perceptions of surveillance, trust, capacity).

<br>
<br>

##### Use Case 2: AI support for mental health
<span class="anchor-s" id="ws5b"></span>
(a) Summarisation & Monitoring: Standardised subjective measures are fundamental to mental health monitoring but have significant limitations: level self-awareness; willingness to complete questionnaires; limited choice of responses. Summaries that capture fluctuations in individuals' state-of-mind, based on heterogeneous sources, while emphasising key clinical concepts, can significantly assist in monitoring, prevention and early detection, augment clinician capacity, present alternatives to standard questionnaires and compensate for reduced access to mental health services.

**Key Challenges:** Fabricated or erroneous information (hallucinations); ethical challenges due to inappropriate generation or missing key events. From an RAI perspective, consideration of integration with current practice and NICE guidelines.

<br>

(b) Self-management interventions: Such interventions have significant beneficial effects, even for people with severe mental illness, reducing symptoms and length of admission in inpatient units, improving social functioning & quality of life beyond end-of-treatment. AI-assisted models can support mental health clinicians and service users in developing shared strategies for self-management, allowing for personalisation in monitoring progress.

**Key Challenges:** Combining monitoring and dialogue technology; understanding how the technology meets patient & clinician needs; acceptability by patients (positively viewed vs fears of abandonment or exclusion); integration challenges with services care.

<br>
<br>

##### Use case 3: AI legal support
<span class="anchor-s" id="ws5c"></span>
The UK legal services market is the second largest in the world, employing >300,000 people and worth ~£43 billion. However, the adoption of legaltech and specifically AI by UK law firms remains limited, hindered by trust. Yet interest in the application of AI, particularly language technology, has surged in recent years, including efforts to create specialised LLMs pre-trained on legal corpora. AI technology and generative LLMs have the potential to transform legal services, promising increased efficiency and robustness. Our use case will focus on: a) summarisation of legal documents used by judicial officials and b) dialogue systems for legal advice. Both are particularly relevant as judges are already allowed to summarise court cases using ChatGPT, and “DIY law” chatbots are being rolled out to give AI-powered legal answers.

**Key Challenges:** Appropriate generation (accurate and suitable information, without hallucination or unnecessary private information) and user-appropriate presentation of information (i.e. legal professionals vs general public). From an RAI perspective, safeguarding against erroneous or inappropriate responses and addressing liability issues in the latter case.